{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Principal Components x Demographic Factors\n",
    "\n",
    "In this notebook, principal components are generated from question topic prevalences and disctionary-based estimates of linguistic patterns — and their relationships to various demographic data are explored through statistical tests.\n",
    "\n",
    "We used a Principle Components Analysis (PCA) in R ('prcomp' function) to integrate multiple variables and conduct an analysis for each question and set of responses. PCA is a multivariate statistical technique that extracts important information about the inter-correlations of multiple variables and re-represents that information as new variables called principle components. These new principle components can then be used to show the similarity and graphic relationships between variables as a way of exploring the data. Because PCA condenses multiple variables into fewer dimensions, the new principle components may also be used to integrate new descriptions of the combined variables. These reified principle components may then be used as covariates to estimate relationships with other variables such as demographic factors.\n",
    "\n",
    "Twenty-seven dictionary-based variables (LIWC, AIC, and Docuscope) were not relevant and were excluded from the analysis, leaving a total of 221 dictionary-based variables in the PCA. This was in addition to the measures of topic prevalence, which each had different numbers of topic variables depending on the question/response type. In order to remove variables with high numbers of 0s (no observations), we set a 0.3 maximum threshold, leaving variable columns with 70% or more observations in the analysis. The number of responses and variables included for each question in the analysis are provided in Table 1. Because of the different scales used by the different dictionaries and topic measures (for example, topic prevalence is 0-1 while AIC is measured on a scale from 1-7), the PCA was based on a correlation matrix. The data were also centered around zero and rotated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.0     ✔ purrr   0.2.5\n",
      "✔ tibble  2.0.1     ✔ dplyr   0.7.8\n",
      "✔ tidyr   0.8.2     ✔ stringr 1.3.1\n",
      "✔ readr   1.3.1     ✔ forcats 0.3.0\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 3.5.2”── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "Warning message:\n",
      "“package ‘FactoMineR’ was built under R version 3.5.2”\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(broom)\n",
    "library(FactoMineR)\n",
    "#library(magrittr) not likely needed since it is now part of tidyverse\n",
    "library(emmeans)\n",
    "library(ggplot2)\n",
    "library(ggExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('../data/merged_artsengagement.rda')\n",
    "load('../data/tidy_questions_best.Rda')\n",
    "source('../scripts/select_helpers.R')\n",
    "load('../data/pca_labels.rda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "motiv_demos <- df %>% select(contains('sr_motivation')) %>% names\n",
    "identity_demos <- df %>% select(contains('sr_identity')) %>% names\n",
    "participation_demos <- df %>% select(all_arts('participation')) %>% select(starts_with('sr')) %>% names\n",
    "real_demos <- c('ethnic_group', 'sex', 'school', 'parented', 'income', 'artsincollege', 'hstype', 'hssize',\n",
    "           'hslocation', 'hs_arts_freq', 'hs_encouragement', 'hs_required', 'hs_fees',\n",
    "           'so_childhood1', 'so_childhood3', 'so_childhood5', 'sr_participated',\n",
    "               'sr_highestdegreeplanned')\n",
    "demo_groups <- c('real_demos','motiv_demos','identity_demos','participation_demos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_demo_prompts <- c(\n",
    "    'Ethnic Group',\n",
    "    'Sex',\n",
    "    'School',\n",
    "    'Highest Parent\\nEducation',\n",
    "    'Family Income',\n",
    "    'Prior to beginning college,\\ndid you expect to be involved in the arts during college?',\n",
    "    'High School Type',\n",
    "    'High School Size',\n",
    "    'High School Location',\n",
    "    'How would you rate the frequency\\nof your overall involvement\\nin arts events and activities during high school?',\n",
    "    'Were you encouraged by your high school to be involved in the arts?',\n",
    "    'Were you required by your high school to be involved in the arts?',\n",
    "    'Was there a fee associated with participation in arts activities at your high school?',\n",
    "    'Were you involved in the arts during your childhood?',\n",
    "    'During your childhood, did your parents sign you up for art classes of any kind?',\n",
    "    'During your childhood, did your parents talk to you about the arts?',\n",
    "    'Arts Participation Senior Year',\n",
    "    'What is the\\nhighest academic degree\\nthat you intend on obtaining?'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used within the mergeQuestion function to merge variable names\n",
    "stripnames <- function(data, question) {\n",
    "    data <- data %>% select('rownums', starts_with(question))\n",
    "    varnames <- names(data)\n",
    "    newnames <- varnames\n",
    "    for (i in seq(3, length(varnames))) {\n",
    "        newnames[i] <- substr(varnames[i], gregexpr(\"\\\\.\\\\.\", varnames[i])[[1]][1]+2, nchar(varnames[i]))\n",
    "    }\n",
    "    names(data) <- newnames\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "# Remove irrelavant variables\n",
    "stripVars <- function(data) {\n",
    "    removenames <- names(data %>% select(matches(\"AIC..Words|AIC..IC_Differentiation|AIC..IC_Integration|AIC..DIAL_Differentiation|AIC..DIAL_Integration|AIC..ELAB_Differentiation|AIC..ELAB_Integration|docuscope..OralCues|docuscope..DialogCues|docuscope..XWordTokens|docuscope..XPunctuationTokens|docuscope..XTokens|LIWC..WC|LIWC..Sixltr|LIWC..Dic|LIWC..WPS|LIWC..swear|LIWC..netspeak|LIWC..assent|LIWC..nonflu|LIWC..filler|LIWC..AllPunc|LIWC..Period|LIWC..Comma|LIWC..Colon|LIWC..SemiC|LIWC..QMark|LIWC..Exclam|LIWC..Dash|LIWC..Quote|LIWC..Apostro|LIWC..Parenth|LIWC..OtherP\")))\n",
    "    data <- data[ , !names(data) %in% removenames]\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "# Merges responses between years\n",
    "mergeQuestion <- function(data, question) {\n",
    "    if (substr(question, 3,3) == '_') {\n",
    "        question <- substr(question, 4, nchar(question))\n",
    "    }\n",
    "    # if you're aware of other prefixes, add them here\n",
    "    yrs <- c(NA,'fl','f1','f2','so','jr','sr','sl')\n",
    "    data$rownums <- seq(nrow(data)) # add rownums so resulting data can be re-integrated\n",
    "    mergeddf <- data.frame()\n",
    "    for (yr in yrs) {\n",
    "        if (question == 'definition' && is.na(yr))\n",
    "            qyr <- question\n",
    "        else if (is.na(yr))\n",
    "            next\n",
    "        else {\n",
    "            qyr <- paste0(yr, '_', question)\n",
    "        }\n",
    "        if (data %>% select(starts_with(qyr)) %>% ncol == 0) { next }\n",
    "        tempdf <- stripnames(data, qyr)\n",
    "        names(tempdf)[2] <- question\n",
    "        mergeddf <- bind_rows(mergeddf, tempdf)        \n",
    "    }\n",
    "    mergeddf <- mergeddf[complete.cases(mergeddf),]\n",
    "    mergeddf <- mergeddf %>% stripVars\n",
    "    rownames(mergeddf) <- c()\n",
    "    return(mergeddf)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter demographics to those within min & max levels (inclusive) into small_demos variable\n",
    "min = 2\n",
    "max = 5\n",
    "temp <- demodfpcs %>% sapply(function(x)(x %>% levels %>% length)) %>% as.data.frame\n",
    "temp$demo <- rownames(temp)\n",
    "temp <- temp %>% filter(. >= min & max >= .)\n",
    "small_demos <- temp %>% pull(demo)\n",
    "small_demos\n",
    "\n",
    "dir_to_save_results = './results'\n",
    "plot_type = 'density_plots' # plural\n",
    "output_format = '.png' # with dot\n",
    "\n",
    "dir.create(dir_to_save_results, showWarnings = F)\n",
    "# for all stm'd questions\n",
    "for(question in question_names[-c(4:6,9:14)]) {\n",
    "    dir.create(paste(dir_to_save_results, question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting, PC creation\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "                                       \n",
    "    # principal component generation\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge PCs with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                        (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "                                       \n",
    "    # separate PCs and demographics\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "                                       \n",
    "    # plotting (by PC)\n",
    "    for(p in seq(pcs)) {\n",
    "        # combine individual PC with demographics\n",
    "        temp <- bind_cols(pcs[p], demodf)\n",
    "        names(temp) <- c(\"pc\", names(temp)[-1])\n",
    "        \n",
    "        # for each demographic...\n",
    "        for(d in seq(small_demos)) {\n",
    "            mu <- temp %>% na.omit %>% group_by_at(vars(small_demos[d])) %>%\n",
    "                    summarise(grp.median=median(pc))\n",
    "\n",
    "            ggplot(na.omit(demodfpcs), aes_string(x=names(pcs)[p], fill=small_demos[d])) +\n",
    "                geom_density(alpha=0.4) +\n",
    "                xlim(round(na.omit(pcs[[p]]) %>% summary %>% tidy %>% .$minimum)-0.5, \n",
    "                     round(na.omit(pcs[[p]]) %>% summary %>% tidy %>% .$maximum)+.5) +\n",
    "                geom_vline(data=mu, aes_string(xintercept='grp.median', color=names(mu)[1]),\n",
    "                         linetype=\"dashed\") +\n",
    "                labs(subtitle=paste0('pos-x: ', pca_labels %>% \n",
    "                      filter(question_name==question) %>% \n",
    "                      select(matches(paste0(p,'_pos'))) %>%\n",
    "                      pull %>% as.character,\n",
    "                     '\\nneg-x: ', pca_labels %>% \n",
    "                      filter(question_name==question) %>% \n",
    "                      select(matches(paste0(p,'_neg'))) %>%\n",
    "                      pull %>% as.character)) +\n",
    "                theme(plot.subtitle = element_text(size=10))\n",
    "\n",
    "            # saving\n",
    "            dir.create(paste(dir_to_save_results, question, names(pcs)[p], sep='/'), showWarnings = F)\n",
    "            dir.create(paste(dir_to_save_results, question, names(pcs)[p], plot_type,sep='/'), showWarnings = F)\n",
    "            ggsave(paste(dir_to_save_results, question, names(pcs)[p], plot_type, \n",
    "                         paste0(small_demos[d], output_format),sep='/'), \n",
    "                   width = 5, height=4)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create('./results', showWarnings = F)\n",
    "for(question in question_names[-c(4:6,9:14,16)]) {\n",
    "    # directories\n",
    "    dir.create(paste('./results', question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting, PC\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                            (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "    # analysis\n",
    "    for(p in c(1,3)) {\n",
    "        # directories\n",
    "        cur_dir <- paste('./results', question, paste0('pc', p, '_pc', p+1, '_marginal_plots'), sep = '/')\n",
    "        dir.create(cur_dir, showWarnings = F)\n",
    "        for(d in seq(demodf)) {\n",
    "            temp <- bind_cols(pcs[p], pcs[p+1], demodf[d])\n",
    "            names(temp) <- c(paste0('pc0'),paste0('pc00'),'demo') # for easier ggplot column selection\n",
    "            if((temp$demo %>% table %>% as.data.frame %>% filter(Freq != 0) %>% nrow) == 1) next\n",
    "\n",
    "            pca_idx <- 0\n",
    "            if (p == 1) {\n",
    "                pca_idx <- 2\n",
    "            }\n",
    "            if (p == 3) {\n",
    "                pca_idx <- 6\n",
    "            }\n",
    "            \n",
    "            # hexbins\n",
    "            plot <- ggplot(temp %>% na.omit, aes(x=pc0, y=pc00, color=demo)) + geom_point(alpha=4/10) +\n",
    "              labs(color=real_demo_prompts[d]) +\n",
    "              theme(legend.position = \"bottom\", text = element_text(size=22)) +\n",
    "              xlab(paste0(as.character(filter(pca_labels, question_name == question)[[pca_idx+1]]),\n",
    "                 ' (-) v. ',\n",
    "                 as.character(filter(pca_labels,question_name == question)[[pca_idx]]), ' (+)')) +\n",
    "              ylab(paste0(as.character(filter(pca_labels,question_name == question)[[pca_idx+3]]),\n",
    "                 ' (-) v. ',\n",
    "                 as.character(filter(pca_labels,question_name == question)[[pca_idx+2]]), ' (+)'))\n",
    "            \n",
    "            if ((question == 'sr_othergrowth' || question == 'sr_society') && p == 1) {\n",
    "                plot <- plot + xlab(paste0(as.character(filter(pca_labels,question_name == question)$pc1_neg),\n",
    "                 ' (-) v.\\n',\n",
    "                 as.character(filter(pca_labels,question_name == question)$pc1_pos), ' (+)'))\n",
    "            }\n",
    "            \n",
    "            plot <- ggMarginal(plot, type='density', groupColour=TRUE)\n",
    "            \n",
    "            size <- 1248\n",
    "            if (d == 3) { # school index\n",
    "                size <- size * 1.5\n",
    "            }\n",
    "            png(paste0(cur_dir, '/pc', p, '_pc', p+1, '_', demodf[d] %>% names, '.png'), width = size, height = size, units = \"px\")\n",
    "            print(plot)\n",
    "            dev.off()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA, EMMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 530\n",
      "[1] 812\n",
      "[1] 971\n",
      "[1] 840\n",
      "[1] 939\n"
     ]
    }
   ],
   "source": [
    "sig_contrasts.demos <- c()\n",
    "sig_aov_posthoc <- c()\n",
    "dir.create('./results', showWarnings = F)\n",
    "for(question in question_names[-c(4:6,9:14)]) {\n",
    "    # directories\n",
    "    dir.create(paste('./results', question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "                                       \n",
    "    # generate principal components\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    # ( each respondent has up to 4 responses per question, and each response is given a weight between 1/4 and 1 )\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                            (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "    # analysis\n",
    "    for(p in seq(pcs)) {\n",
    "        # creating directories\n",
    "        dir.create(paste('./results', question, names(pcs)[p], sep = '/'), showWarnings = F)\n",
    "        dir.create(paste('./results', question, names(pcs)[p], 'emmeans', sep = '/'), showWarnings = F)\n",
    "        dir.create(paste('./results', question, names(pcs)[p], 'anova_tukey', sep = '/'), showWarnings = F)\n",
    "        for(d in seq(demodf)) {\n",
    "            temp <- bind_cols(pcs[p], demodf[d])\n",
    "            names(temp) <- c('pc','demo')\n",
    "            if((temp$demo %>% table %>% as.data.frame %>% filter(Freq != 0) %>% nrow) == 1) next\n",
    "\n",
    "            # emmeans contrasts\n",
    "            lm.out <- lm(pc ~ demo, data=temp, na.action = na.exclude)\n",
    "            em.out <- emmeans(lm.out, ~ demo, data=temp, weights = 'proportional')\n",
    "            contrast.out <- contrast(em.out, method=\"del.eff\") %>% tidy\n",
    "\n",
    "            contrast.out$p.value %<>% p.adjust(method='holm')\n",
    "            contrast.out %<>% mutate(question_name=question,\n",
    "                                        PC_num = paste0('PC',p), \n",
    "                                        PC_pos = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_pos'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        PC_neg = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_neg'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        demographic = names(demodf)[d]\n",
    "                                     )            \n",
    "\n",
    "            # anova tukey\n",
    "            aov.out <- aov(pc ~ demo, data=temp) %>% TukeyHSD %>% tidy\n",
    "            aov.out %<>% select(-term) %>% mutate(question_name=question,\n",
    "                                        PC_num = paste0('PC',p), \n",
    "                                        PC_pos = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_pos'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        PC_neg = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_neg'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        demographic = names(demodf)[d]\n",
    "                                     )\n",
    "            \n",
    "            # bind rows\n",
    "            options(warn=-1)\n",
    "            sig_contrasts.demos %<>% bind_rows(contrast.out)\n",
    "            sig_aov_posthoc %<>% bind_rows(aov.out)\n",
    "            options(warn=0)\n",
    "            \n",
    "            # write csvs\n",
    "            write.csv(contrast.out, paste('./results',question,names(pcs)[p],'emmeans',paste0(names(demodf)[d],'.csv'),sep='/'))\n",
    "            write.csv(aov.out, paste('./results',question,names(pcs)[p],'anova_tukey',paste0(names(demodf)[d],'.csv'),sep='/'))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# # write rdas\n",
    "save(sig_contrasts.demos, file='./results/emmeans_contrasts.rda')\n",
    "save(sig_aov_posthoc, file='./results/anova_tukey.rda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip aftercollege bc it causes errors (index 7)\n",
    "for(question in (question_names[-c(4:6,9:14)])[-7]) {\n",
    "    # directories\n",
    "    dir.create(paste('./results', question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting, PC\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                            (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "    # manova\n",
    "    demo_level_nums <- demodf %>% na.omit %>% sapply(function(x)(x %>% table %>% as.data.frame %>% filter(Freq != 0) %>% nrow)) %>% as.data.frame\n",
    "    demo_level_nums$demo <- rownames(demo_level_nums)\n",
    "    names(demo_level_nums) <- c('n','demo')\n",
    "    filter_list <- demo_level_nums %>% filter(n < 2) %>% pull(demo)\n",
    "    man_demodf <- demodf %>% select(-filter_list)\n",
    "    print(nrow(man_demodf))\n",
    "    man.out <- manova(pcs %>% as.matrix ~ .,\n",
    "                    data=man_demodf)\n",
    "                                                     \n",
    "    # write csv\n",
    "    write.csv(tidy(man.out), paste('./results',question,'manova_table.csv',sep='/'))\n",
    "    sink(paste('./results',question,'manova_output.txt',sep='/'))\n",
    "    print(man.out)\n",
    "    sink()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
